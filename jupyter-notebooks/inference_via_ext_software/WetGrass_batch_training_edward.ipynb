{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WetGrass analyzed using Edward (batch_size > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import edward as ed\n",
    "import edward.models as edm\n",
    "import edward.inferences as edi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bob/Notebooks/Quantum/quantum-fog/jupyter-notebooks/inference_via_ext_software\n",
      "/home/bob/Notebooks/Quantum/quantum-fog\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "cur_dir_path = os.getcwd()\n",
    "print(cur_dir_path)\n",
    "os.chdir('../../')\n",
    "qfog_path = os.getcwd()\n",
    "print(qfog_path)\n",
    "sys.path.insert(0,qfog_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BayesNet object bnet from bif file\n",
    "import importlib\n",
    "mm = importlib.import_module(\"jupyter-notebooks.inference_via_ext_software.ModelMaker\")\n",
    "from graphs.BayesNet import *\n",
    "in_path = \"examples_cbnets/WetGrass.bif\"\n",
    "bnet = BayesNet.read_bif(in_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model (with placeholders for Cloudy and WetGrass) from bnet\n",
    "file_prefix = \"examples_cbnets/WetGrass\"\n",
    "vtx_to_data = {'Cloudy': [1], \"WetGrass\": [0, 1]}\n",
    "batch_size = 100\n",
    "mm.ModelMaker.write_edward_model(file_prefix, bnet, vtx_to_data=vtx_to_data,\n",
    "                                sample_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".py file with model can be found here\n",
    "\n",
    "<a href=\"../../examples_cbnets/WetGrass_edward.py\">\n",
    "../../examples_cbnets/WetGrass_edward.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -i option allows it to access notebook's namespace\n",
    "%run -i examples_cbnets/WetGrass_edward.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate training data\n",
    "#[Cloudy, WetGrass] = [0, 1] all the time\n",
    "data_size = 1000\n",
    "data = np.tile([0, 1], [data_size, 1])\n",
    "data\n",
    "\n",
    "# [Cloudy, WetGrass] = [0, 1] most of time\n",
    "# data_size = 10000\n",
    "# bern = np.random.binomial\n",
    "# data = np.stack( \n",
    "#     [[bern(1, .1), bern(1, .9)] for _ in range(data_size)])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 # number of full passes, cycles, over data\n",
    "num_batches = data_size//batch_size\n",
    "assert batch_size*num_batches == data_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [100%] ██████████████████████████████ Elapsed: 4s | Loss: 703.859\n"
     ]
    }
   ],
   "source": [
    "q_dict = {Rain: Rain_q, Sprinkler: Sprinkler_q}\n",
    "data_dict = {Cloudy: Cloudy_ph, WetGrass: WetGrass_ph}\n",
    "inf = edi.KLqp(q_dict, data=data_dict)\n",
    "n_iter = num_batches*num_epochs\n",
    "scale = {Cloudy:num_batches, WetGrass:num_batches}\n",
    "inf.initialize(n_iter=n_iter, n_samples=5, scale=scale)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "bgen = mm.ModelMaker.batch_gen([data[:, 0], data[:,1]], batch_size)\n",
    "for i in range(inf.n_iter):\n",
    "    Cloudy_bat, WetGrass_bat = next(bgen)\n",
    "    info_dict = inf.update({Cloudy_ph: Cloudy_bat, WetGrass_ph: WetGrass_bat})\n",
    "    inf.print_progress(info_dict)\n",
    "inf.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rain\n",
      "[ 0.03795076  0.96204931]\n",
      "\n",
      "Sprinkler\n",
      "[ 0.033005  0.966995]\n"
     ]
    }
   ],
   "source": [
    "# print final prob distributions\n",
    "\n",
    "print('\\nRain')\n",
    "print(Rain_q.probs.eval())\n",
    "\n",
    "print('\\nSprinkler')\n",
    "print(Sprinkler_q.probs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
